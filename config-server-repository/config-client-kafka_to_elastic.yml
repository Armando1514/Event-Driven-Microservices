server:
  port: 8182

kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  topic-name: twitter-topic
  topic-names-to-create:
    - twitter-topic
  num-of-partitions: 3
  replication-factor: 3

retry-config:
  initial-interval-ms: 1000
  max-interval-ms: 10000
  multiplier: 2.0
  maxAttempts: 3
  sleep-time-ms: 2000

kafka-consumer-config:
  # Since we read serialized data from the topic, the consumer has to know how to deserialize it.
  key-deserializer: org.apache.kafka.common.serialization.LongDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  # Sets a unique id for a consumer to allow using offsets (so we don't start from beginning everytime)
  consumer-group-id: twitter-topic-consumer
  # We say that we want to start reading from the beginning of partition.
  auto-offset-reset: earliest
  # we work with avro type so we have to set this properties to true.
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  # This property allows to consume data in batches
  batch-listener: true
  # We want to start listening from topic after checking the topic is already there
  auto-startup: false
  # Sets the number of threads to work on consuming, required for maximum concurrency.
  # E.g. 1 topic, 4 partitions -> Set as 4
  concurrency-level: 3
  # It says that in this time the broker has to receive at least one heartbeat from the consumer, otherwise consider it broken
  session-timeout-ms: 10000
  # Specify the frequence of heartbeat from the consumer to the broker.
  heartbeat-interval-ms: 3000
  # This property is for user threads. If message processing logic is too heavy to cause larger than this time.
  # Coordinator explicitly have the consumer leave the group and also triggers
  # a new round of rebalance
  max-poll-interval-ms: 300000
  # Set the maximum records to fetch in each poll
  max-poll-records: 500
  # maximum bytes to fetch in each poll
  max-partition-fetch-bytes-default: 1048576
  max-partition-fetch-bytes-boost-factor: 1
  # how long we will wait until at least one record is available.
  # it will block in the poll method on kafka consumer nad wait this time for the new records.
  # too high will block too much and too low will cost CPU stall = CPU doesn't make progress although it is running.
  poll-timeout-ms: 150

elastic-config:
  index-name: twitter-index
  connection-url: http://localhost:9200
  connect-timeout-ms: 5000
  socket-timeout-ms: 30000
  is-repository: true