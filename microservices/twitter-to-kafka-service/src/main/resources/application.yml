twitter-to-kafka-service:
  twitter-keywords:
    - Java
    - Microservices
    - Spring
    - Kafka
    - Elasticsearch
    - Maradona
    - Naples
  enable-mock-tweets: true
  mock-min-tweet-length: 5
  mock-max-tweet-length: 15
  mock-sleep-ms: 1000

retry-config:
  initial-interval-ms: 1000
  max-interval-ms: 1000
  multiplier: 2.0
  maxAttempts: 3
  sleep-time-ms: 2000

kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url: http://localhost:8081
  topic-name: twitter-topic
  topic-names-to-create:
    - twitter-topic
  num-of-partitions: 3
  replication-factor: 3

kafka-producer-config:
  # key will be a long
  key-serializer-class: org.apache.kafka.common.serialization.LongSerializer
  # value will be a kafkaAvroSerializer
  value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
  # Data will be compressed with the specific snappy (compression library from Google)
  compression-type: snappy
  # We want to get acknowledge from all the broker replicas to be more resilient
  acsk: all
  batch-size: 16384
  # Tune for higher througput, maximum of tune is + 100 from default value
  batch-size-boost-factor: 100
  # 5ms add a delay on producer, useful in case of light load
  linger-ms: 5
  # After 6 seconds if not ack comes producer throw timeoutError
  request-timeout-ms: 60000
  # Retry max 5 times in case of error
  retry-count: 5